{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import path\n",
    "path.append(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "This notebook is just for some simple tests over the \"impossible to interpret\" scripts provided by the authors. I will try especially the data related part, since it is very weird the way they decided to handle it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from repeat_src.utils.models import get_backbone_model\n",
    "from os.path import join as join_paths\n",
    "from numpy import expand_dims, array\n",
    "from pandas import read_csv\n",
    "from keras.preprocessing import image\n",
    "from keras_vggface.utils import preprocess_input\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import List\n",
    "from glob import glob\n",
    "\n",
    "def load_images(file_list: List[str], batch_size: int) -> array:\n",
    "    if batch_size>len(file_list):\n",
    "        batch_size=len(file_list)\n",
    "        \n",
    "    count: int = 0\n",
    "    x: list = []\n",
    "    for path in file_list:\n",
    "        x_temp = image.load_img(path)\n",
    "        x_temp = image.img_to_array(x_temp)\n",
    "        x_temp = expand_dims(x_temp, axis=0)\n",
    "        x_temp= preprocess_input(x_temp, version=2)\n",
    "        \n",
    "        count += 1\n",
    "        x.append(x_temp)\n",
    "        if count % batch_size == 0 and count != 0:\n",
    "            x = array(x)\n",
    "            x = x.reshape(batch_size, 256, 256, 3)\n",
    "            yield x\n",
    "            x = []\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape: tuple = (256, 256, 3)\n",
    "batch_size: int = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_notop_vgg16.h5\n",
      "58916864/58909280 [==============================] - 2s 0us/step\n",
      "58925056/58909280 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "model = get_backbone_model(input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of unique videos (join video and utterance from the table with ground truths)\n",
    "validation_ground_truth_df = read_csv(\"../omg_ValidationVideos.csv\")\n",
    "\n",
    "video_id_list: list = validation_ground_truth_df.apply(\n",
    "    lambda x: f\"{x['video']}/{x['utterance'].split('.')[0]}\", axis=1\n",
    ").tolist()\n",
    "\n",
    "paths_to_faces = [\n",
    "    join_paths(\"/data/leonardo/OMGEmotionChallenge/Validation_Set/trimmed_faces/\", video_id)\n",
    "    for video_id in video_id_list\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_to_faces = paths_to_faces[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-f8faf0eaf31c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mextracted_features\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mcurrent_video_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpaths_to_faces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Extracting features w/ VGG16-Face'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mvideo_frames_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin_paths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_video_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"*.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     current_video_features = model.predict_generator(\n",
      "\u001b[0;32m~/miniconda3/envs/omg-winner-code/lib/python3.6/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0munit_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munit_scale\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munit_scale\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0munit_scale\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_printer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mncols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproxy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplayed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/omg-winner-code/lib/python3.6/site-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36mstatus_printer\u001b[0;34m(_, total, desc, ncols)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;31m# Prepare IPython progress bar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mIProgress\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# #187 #451 #558 #872\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWARN_NOIPYW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIProgress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "extracted_features: list = []\n",
    "for current_video_path in tqdm(paths_to_faces, desc='Extracting features w/ VGG16-Face'):\n",
    "    video_frames_paths = glob(join_paths(current_video_path, \"*.png\"))\n",
    "\n",
    "    current_video_features = model.predict_generator(\n",
    "        load_images(video_frames_paths, batch_size),\n",
    "        (len(video_frames_paths) // batch_size) + 1,\n",
    "        verbose=1,\n",
    "    )\n",
    "    extracted_features.append(current_video_features)\n",
    "    # df_cnn=df_cnn[0:len(idict[k]),:]\n",
    "    # df_cnn=pd.DataFrame(df_cnn)\n",
    "    # df_cnn.to_csv(predict_path+k+'.csv',index=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_features_extracted = pd.read_csv(\"./extracted_features/Validation_Set/0cf41d04d_1/utterance_28.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(304, 512)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_features_extracted.values.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape is `(frame_number, VGG_output_shape)`. However, the number of frame is slightly larger than the actual number, since it has to be a power of the batch size (in this case 16). I believe, when the number of frames is not enough, new frames are created from the last one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_example_path: str = \"/data/leonardo/OMGEmotionChallenge/Validation_Set/audio/0cf41d04d_1/utterance_28.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "dlopen(/Users/leonardoalchieri/miniconda3/envs/omg-winner-code/lib/python3.8/site-packages/audresample/core/bin/libaudresample.dylib, 0x0006): tried: '/Users/leonardoalchieri/miniconda3/envs/omg-winner-code/lib/python3.8/site-packages/audresample/core/bin/libaudresample.dylib' (mach-o file, but is an incompatible architecture (have (x86_64), need (arm64e)))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/Users/leonardoalchieri/Desktop/GIT/OMGWinnerCode/repeat_experiments.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/leonardoalchieri/Desktop/GIT/OMGWinnerCode/repeat_experiments.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mopensmile\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/leonardoalchieri/Desktop/GIT/OMGWinnerCode/repeat_experiments.ipynb#X23sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m smile \u001b[39m=\u001b[39m opensmile\u001b[39m.\u001b[39mSmile(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/leonardoalchieri/Desktop/GIT/OMGWinnerCode/repeat_experiments.ipynb#X23sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     feature_set\u001b[39m=\u001b[39mopensmile\u001b[39m.\u001b[39mFeatureSet\u001b[39m.\u001b[39mComParE_2016,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/leonardoalchieri/Desktop/GIT/OMGWinnerCode/repeat_experiments.ipynb#X23sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     feature_level\u001b[39m=\u001b[39mopensmile\u001b[39m.\u001b[39mFeatureLevel\u001b[39m.\u001b[39mFunctionals,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/leonardoalchieri/Desktop/GIT/OMGWinnerCode/repeat_experiments.ipynb#X23sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/leonardoalchieri/Desktop/GIT/OMGWinnerCode/repeat_experiments.ipynb#X23sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m y \u001b[39m=\u001b[39m smile\u001b[39m.\u001b[39mprocess_file(audio_example_path)\n",
      "File \u001b[0;32m~/miniconda3/envs/omg-winner-code/lib/python3.8/site-packages/opensmile/__init__.py:6\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mopensmile\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m config\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mopensmile\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdefine\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      3\u001b[0m     FeatureSet,\n\u001b[1;32m      4\u001b[0m     FeatureLevel,\n\u001b[1;32m      5\u001b[0m )\n\u001b[0;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mopensmile\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msmile\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      7\u001b[0m     Smile,\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     11\u001b[0m __all__ \u001b[39m=\u001b[39m []\n\u001b[1;32m     14\u001b[0m __version__ \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39munknown\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/omg-winner-code/lib/python3.8/site-packages/opensmile/core/smile.py:10\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39maudeer\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39maudinterface\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39maudobject\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mopensmile\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mSMILEapi\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     14\u001b[0m     OpenSMILE,\n\u001b[1;32m     15\u001b[0m     FrameMetaData,\n\u001b[1;32m     16\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/omg-winner-code/lib/python3.8/site-packages/audinterface/__init__.py:26\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Generic processing interfaces.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[39m:mod:`audinterface` provides you classes\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m \n\u001b[1;32m     25\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39maudinterface\u001b[39;00m \u001b[39mimport\u001b[39;00m utils\n\u001b[1;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39maudinterface\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfeature\u001b[39;00m \u001b[39mimport\u001b[39;00m Feature\n\u001b[1;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39maudinterface\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprocess\u001b[39;00m \u001b[39mimport\u001b[39;00m Process\n",
      "File \u001b[0;32m~/miniconda3/envs/omg-winner-code/lib/python3.8/site-packages/audinterface/utils/__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39maudinterface\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     read_audio,\n\u001b[1;32m      3\u001b[0m     signal_index,\n\u001b[1;32m      4\u001b[0m     sliding_window,\n\u001b[1;32m      5\u001b[0m     to_timedelta,\n\u001b[1;32m      6\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/omg-winner-code/lib/python3.8/site-packages/audinterface/core/utils.py:10\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39maudeer\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39maudformat\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39maudresample\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39maudiofile\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39maf\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39maudinterface\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     14\u001b[0m     Timestamp,\n\u001b[1;32m     15\u001b[0m     Timestamps,\n\u001b[1;32m     16\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/omg-winner-code/lib/python3.8/site-packages/audresample/__init__.py:2\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39maudresample\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m define\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39maudresample\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      3\u001b[0m     am_fm_synth,\n\u001b[1;32m      4\u001b[0m     remix,\n\u001b[1;32m      5\u001b[0m     resample,\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39maudresample\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m config\n\u001b[1;32m     10\u001b[0m __all__ \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/omg-winner-code/lib/python3.8/site-packages/audresample/core/api.py:8\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39maudresample\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m \u001b[39mimport\u001b[39;00m define\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39maudresample\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m config\n\u001b[0;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39maudresample\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlib\u001b[39;00m \u001b[39mimport\u001b[39;00m lib\n\u001b[1;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_signal\u001b[39m(\n\u001b[1;32m     12\u001b[0m         signal: np\u001b[39m.\u001b[39mndarray,\n\u001b[1;32m     13\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray:\n\u001b[1;32m     14\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Ensure float32 and two dimensions.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/omg-winner-code/lib/python3.8/site-packages/audresample/core/lib.py:22\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# pragma: no cover\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUnsupported platform\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 22\u001b[0m lib \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39;49mcdll\u001b[39m.\u001b[39;49mLoadLibrary(lib_path)\n\u001b[1;32m     25\u001b[0m \u001b[39m# resample\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mConverterConfig\u001b[39;00m(ctypes\u001b[39m.\u001b[39mStructure):\n",
      "File \u001b[0;32m~/miniconda3/envs/omg-winner-code/lib/python3.8/ctypes/__init__.py:451\u001b[0m, in \u001b[0;36mLibraryLoader.LoadLibrary\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mLoadLibrary\u001b[39m(\u001b[39mself\u001b[39m, name):\n\u001b[0;32m--> 451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dlltype(name)\n",
      "File \u001b[0;32m~/miniconda3/envs/omg-winner-code/lib/python3.8/ctypes/__init__.py:373\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_FuncPtr \u001b[39m=\u001b[39m _FuncPtr\n\u001b[1;32m    372\u001b[0m \u001b[39mif\u001b[39;00m handle \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 373\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle \u001b[39m=\u001b[39m _dlopen(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name, mode)\n\u001b[1;32m    374\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    375\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle \u001b[39m=\u001b[39m handle\n",
      "\u001b[0;31mOSError\u001b[0m: dlopen(/Users/leonardoalchieri/miniconda3/envs/omg-winner-code/lib/python3.8/site-packages/audresample/core/bin/libaudresample.dylib, 0x0006): tried: '/Users/leonardoalchieri/miniconda3/envs/omg-winner-code/lib/python3.8/site-packages/audresample/core/bin/libaudresample.dylib' (mach-o file, but is an incompatible architecture (have (x86_64), need (arm64e)))"
     ]
    }
   ],
   "source": [
    "import opensmile\n",
    "\n",
    "smile = opensmile.Smile(\n",
    "    feature_set=opensmile.FeatureSet.ComParE_2016,\n",
    "    feature_level=opensmile.FeatureLevel.Functionals,\n",
    ")\n",
    "y = smile.process_file(audio_example_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('omg-winner-code')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "79044589b91cfb6c32036710470c4c8458b3797b7fcf568ec5cf0cbce1d238a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
